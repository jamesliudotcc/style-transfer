{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.keras.datasets.mnist.load_data\n",
    "mnist = tf.keras.datasets.mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that each MNIST image is a 28 x 28 bitmap. Here is one line. At the edge, of course it is all 0.\n",
    "\n",
    "The Tensorflow docs provide:\n",
    "\n",
    "> Returns\n",
    "> Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "\n",
    "> `x_train, x_test`: uint8 arrays of grayscale image data with shapes (num_samples, 28, 28).\n",
    "\n",
    "> `y_train, y_test`: uint8 arrays of digit labels (integers in range 0-9) with shapes (num_samples,). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 10000, 10000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist[0][0]), len(mnist[0][1]), len(mnist[1][0]), len(mnist[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 60,000 training, 10,000 testing.\n",
    "\n",
    "We know that they are 28x28 matrices. Let's take a look at one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, that is very hard to understand. Let's see one plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(mnist[0][0][0], cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently that is supposed to be a 5. Humans have such bad handwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little cleanup before we go on\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[0].shape[1]\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "# change our image type to float32 data type\n",
    "x_train = x_train.astype('float32') #uint8 originally\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize our data by changing the range from (0 to 255) to (0 to 1)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Do one hot encoding on the labels:\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "num_classes=y_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD \n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# Our First Convolution Layer, Filter size 32 which reduces our layer size to 26 x 26 x 32\n",
    "# We use ReLU activation and specify our input_shape which is 28 x 28 x 1\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Our Second Convolution Layer, Filter size 64 which reduces our layer size to 24 x 24 x 64\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# We use MaxPooling with a kernel size of 2 x 2, this reduces our size to 12 x 12 x 64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# We use a dropout P setting of 0.25 to reduce overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# We then Flatten our tensor object before input into our Dense Layer\n",
    "# A flatten operation on a tensor reshapes the tensor to have the shape that is \n",
    "# equal to the number of elements contained in tensor\n",
    "# In our CNN it goes from 12 * 12 * 64 to 9216 * 1\n",
    "model.add(Flatten())\n",
    "\n",
    "# We connect this layer to a Fully Connected/Dense layer of size 1 * 128\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# We use another Dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# We create our final Fully Connected/Dense layer with an output for each class (10)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# We compile our model, this creates an object that stores the model we just created\n",
    "# We set our Optimizer to use Stochastic Gradient Descent (learning rate of 0.01)\n",
    "# We set our loss function to be categorical_crossentropy as it's suitable for multiclass problems\n",
    "# Finally, the metrics (What we judge our performance on) to be accuracy\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = SGD(0.01),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# We can use the summary function to display our model layers and parameters\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1404 - accuracy: 0.9581 - val_loss: 0.0662 - val_accuracy: 0.9795\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1203 - accuracy: 0.9637 - val_loss: 0.0585 - val_accuracy: 0.9806\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1063 - accuracy: 0.9687 - val_loss: 0.0544 - val_accuracy: 0.9828\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1003 - accuracy: 0.9696 - val_loss: 0.0495 - val_accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0904 - accuracy: 0.9724 - val_loss: 0.0444 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0829 - accuracy: 0.9747 - val_loss: 0.0443 - val_accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0798 - accuracy: 0.9757 - val_loss: 0.0415 - val_accuracy: 0.9865\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0733 - accuracy: 0.9776 - val_loss: 0.0395 - val_accuracy: 0.9875\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: 0.0373 - val_accuracy: 0.9875\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0665 - accuracy: 0.9796 - val_loss: 0.0350 - val_accuracy: 0.9889\n",
      "Test loss: 0.03498220071196556\n",
      "Test accuracy: 0.9889000058174133\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Store our results here so we can plot later\n",
    "# In our fit function we specify our datsets (x_train & y_train), \n",
    "# the batch size (typically 16 to 128 depending on your RAM), the number of \n",
    "# epochs (usually 10 to 100) and our validation datasets (x_test & y_test)\n",
    "# verbose = 1, sets our training to output performance metrics every epoch\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (x_test, y_test))\n",
    "\n",
    "# We obtain our accuracy score using the evalute function\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnist_sample_cnn_10_epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t3\t0\t3\t5\t"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "figure = plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(5):\n",
    "    figure.add_subplot(1,5,i+1)\n",
    "    random_idx = np.random.randint(0,len(x_test))\n",
    "    plt.imshow(x_test[random_idx,:,:,0],cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    print(np.squeeze(\n",
    "        np.argmax(\n",
    "            model.predict(\n",
    "                x_test[random_idx].reshape(1,28,28,1)\n",
    "            ),\n",
    "            axis=1),\n",
    "        axis=0),end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
